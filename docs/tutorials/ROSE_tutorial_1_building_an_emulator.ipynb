{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a49da0",
   "metadata": {},
   "source": [
    "# Building and Optimizing an Emulator\n",
    "\n",
    "Let's build an emulator for a quantum scattering problem with an optical potential! We will choose neutron scattering on the $^{40}$ Ca nucleus as our test problem. In particular, we want to build an emulator that can predict the differential elastic scattering cross section for this reaction, at a given energy as quickly and accurately as possible. \n",
    "\n",
    "We have the following Hamiltonian as the radial part of the scattering equation:\n",
    "\n",
    "\\begin{equation}\n",
    "    F_\\alpha(\\phi)=\\left(-\\frac{d^2}{dr^2}+\\frac{\\ell(\\ell+1)}{r^2}+U(r,\\alpha)-p^2\\right)\\phi(r)=0,\n",
    "\\end{equation}\n",
    "\n",
    "where a system with reduced mass $\\mu$ interacts through a potential $V(r,\\alpha)=U(r,\\alpha)/2\\mu$ with parameters $\\alpha$, $\\ell$ is the angular momentum quantum number, and $p$ is the asymptotic linear momentum. In the code implementation we re-scale the equation to work in dimensionless units $s=rp$. Our reduced basis expansion of $n$ basis can be written as:\n",
    "\n",
    "\\begin{equation}\n",
    "   \\phi(r) \\approx \\phi_0(r) + \\sum_k^n a_k\\phi_k(r)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The goal of this tutorial is to demonstrate how to build such an emulator with ROSE, and then choose the optimal emulator configuration to accomplish this. For a video and other notebook resources on ROSE [check this link](https://indico.cern.ch/event/1223721/contributions/5394829/). The full derivation of the involved equations, both for the high fidelity and the reduced basis counter part, will be presented in an upcoming publication and linked here.\n",
    "\n",
    "\n",
    "Let's get to it then. First, we'll import all the modules we need and set up the scattering system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f333f2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.7.dev12+g8ec385d.d20230926\n"
     ]
    }
   ],
   "source": [
    "# pip install nuclear-rose (if you don't have it already)\n",
    "# pip install nuclear-rose==0.9.4a0 \n",
    "# import ROSE to construct the emulator\n",
    "import rose\n",
    "\n",
    "# other nice things\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from scipy.stats import qmc\n",
    "\n",
    "# import stuff for nice plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import scipy.stats as sps\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "print(rose.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecce4b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Starting_time=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02128129",
   "metadata": {},
   "source": [
    "## Setting up the Scattering System\n",
    "\n",
    "We start by making some preliminary definitions for constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05effeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 40  # mass of the target\n",
    "\n",
    "AMU = 931.494102  # MeV/c^2, Particle Data Group\n",
    "MASS_N = 1.008665 * AMU  # MeV/c^2 PDG\n",
    "MASS_P = 1.007276 * AMU  # MeV/c^2 PDG\n",
    "MASS_CHARGED_PION = 139.57039  # MeV/c^2\n",
    "B_40CA = 342.0522  # BMEX\n",
    "\n",
    "MASS_40CA = 20 * MASS_P + 20 * MASS_N - B_40CA\n",
    "MU = (\n",
    "    MASS_40CA * MASS_N / (MASS_40CA + MASS_N)\n",
    ")  # reduced mass - we will do calculations in COM frame\n",
    "\n",
    "# asymptotic energy and wavenumber in center-of-mass (COM) frame\n",
    "energy = 14.1  # MeV\n",
    "k = np.sqrt(2 * MU * energy) / rose.constants.HBARC\n",
    "\n",
    "# how many partial waves should we calculate?\n",
    "l_max = 10\n",
    "l_list = list(range(l_max + 1))\n",
    "\n",
    "# domain of the differential cross section; the observable we want to emulate\n",
    "angles = np.linspace(1, 179, 179)\n",
    "# ROSE also has a convenient grid over radial space we can steal\n",
    "rho = rose.constants.DEFAULT_RHO_MESH.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0abb499",
   "metadata": {},
   "source": [
    "## Define the Interaction: an Optical Potential\n",
    "\n",
    "Let's define the functional forms for the interaction potentials we will use. We will use standard forms of the optical potential, with default parameters for $^{40}$Ca, as defined by [Koning and Delaroche](https://www.sciencedirect.com/science/article/pii/S0375947402013210?casa_token=qS1v6U4xDQEAAAAA:NIi9D5LpP3f05AMwRnvbQ6or8hSvXoEIgKBV56KA4l9aObCOVDAndmuCeIH77iuzoXMOOlAMyw). \n",
    "\n",
    "The potential we use includes the following terms, each with a set of parameters:\n",
    "\n",
    "1. complex volume term with a Woods-Saxon shape; $V_v$, $W_v$, $R_v$, $a_v$\n",
    "2. imaginary surface-peaked term with a Woods-Saxon derivative shape; $W_d$, $R_d$, $a_d$\n",
    "3. complex spin-orbit (SO) coupling term with a Woods-Saxon derivative shape; $V_{so}$, $W_{so}$, $R_{so}$, $a_{so}$.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{aligned}\n",
    "      &V(r;\\alpha,\\ell,j) =-V_v f_\\text{WS}(r,R_v,a_v) - iW_v f_\\text{WS}(r,R_v,a_v) \\\\\n",
    "      &-i4a_dW_d \\frac{d}{dr}f_\\text{WS}(r,R_d,a_d) \\\\\n",
    "      &+2\\ell\\cdot s V_{so}  \\Big(\\frac{\\hbar}{m_\\pi c}\\Big)^2 \\frac{1}{r} \\frac{d}{dr}f_\\text{WS}(R_{so},a_{so}),\n",
    "    \\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The Woods-Saxon functional form (and it's derivative) is our model for the geometric shape of the effective potential the neutron feels as a function of it's distance from the $^{40}$ Ca nucleus. It looks like this:\n",
    "\n",
    "\\begin{equation}\n",
    "f(r;R,a) = \\frac{1}{1 - \\exp{\\frac{r-R}{a}}}.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "All depth parameters ($V_i$, $W_i$) are given in MeV, and geometric parameters $r_i$ and $a_i$ are given in fm. We define our vector of parameters as \n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{\\alpha} = \\begin{bmatrix}\n",
    "V_v &  W_v & R_v & a_v & W_d & R_d & a_d & V_{so} & W_{so} & R_{so} & a_{so}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Let's set this up:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24b9e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of interaction for volume term\n",
    "def wood_saxon(r, R, a):\n",
    "    return 1 / (1 + np.exp((r - R) / a))\n",
    "\n",
    "\n",
    "# shape of interaction for surface-peaked and spin-orbit coupling terms\n",
    "def wood_saxon_prime(r, R, a):\n",
    "    return -1 / a * np.exp((r - R) / a) / (1 + np.exp((r - R) / a)) ** 2\n",
    "\n",
    "\n",
    "# total potential with a real and central term (with the same geometry)\n",
    "# and imaginary surface-peaked term, but no SO coupling\n",
    "def optical_potential(r, theta):\n",
    "    Vv, Wv, Wd, Vso, Wso, Rv, Rd, Rso, av, ad, aso = theta\n",
    "    return (1j * Wv - Vv) * wood_saxon(r, Rv, av) - (4j * ad * Wd) * wood_saxon_prime(\n",
    "        r, Rd, ad\n",
    "    )\n",
    "\n",
    "\n",
    "# spin orbit interaction constant\n",
    "mso = rose.constants.HBARC / MASS_CHARGED_PION\n",
    "\n",
    "\n",
    "# spin-orbit (SO) coulpling term - a function of l dot s, l being the orbital angular momentum\n",
    "# and s being the spin of the neutron\n",
    "def spin_orbit_potential(r, theta, ldots):\n",
    "    Vv, Wv, Wd, Vso, Wso, Rv, Rd, Rso, av, ad, aso = theta\n",
    "    return (Vso + 1j * Wso) * mso**2 * ldots * wood_saxon_prime(r, Rso, aso) / r\n",
    "\n",
    "\n",
    "# the total number of parameters\n",
    "nparams = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2617cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the default parameters determined by Koning & Delaroche\n",
    "VvKD = 46.7238\n",
    "WvKD = 1.72334\n",
    "WdKD = -7.2357\n",
    "VsoKD = 6.1\n",
    "WsoKD = -3.1\n",
    "\n",
    "RvKD = 4.0538\n",
    "RdKD = 4.4055\n",
    "RsoKD = 1.01 * 40 ** (1.0 / 3.0)\n",
    "\n",
    "avKD = 0.6718\n",
    "adKD = 0.5379\n",
    "asoKD = 0.60\n",
    "\n",
    "# This is the value of the parameters coming from the Koning-Delaroche parametrization.\n",
    "# Taken from https://www-nds.iaea.org/RIPL-3/\n",
    "alphaCentral = np.array(\n",
    "    [VvKD, WvKD, WdKD, VsoKD, WsoKD, RvKD, RdKD, RsoKD, avKD, adKD, asoKD]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeba520",
   "metadata": {},
   "source": [
    "## Set up the Training and Testing Regions for the Emulator\n",
    "\n",
    "It is now our goal to define an emulator that, given an arbitrary point in a closed subset of this 11D space, reproduces the scattering solutions of the Schrödinger equation for the center-of-mass frame of a 14.1 MeV neutron and a $^{40}$ Ca nucleus. To do this, we will use a high-fidelity (HF) solver to construct a basis of solutions as we perturb $\\boldsymbol{\\alpha}$ around our region of interest, and then construct a suitable reduced basis emulator from it. \n",
    "\n",
    "Notice that the functional form of the Woods-Saxon (and its derivative) is not a simple linear function of the parameters $R$ and $a$. To be more precise, we can't factorize this function into the product of functions of just the parameters $R$ and $a$, and another function of just the domain of the problem $r$. A mathematician would say that this operator is not \"affine\" in the geometric parameters. To handle emulating the potential operator, we will need to construct an approximation that is factorizable using something called the Empirical Interplation Method (EIM). Chapters 2 and 3 of [this book](https://dr.ascsn.net/) contain a more detail view (within a nuclear physics context) of the reduced basis method and the empirical interpolation method we use in ROSE. \n",
    "\n",
    "In summary, the EIM consists of approximating the potential with $m$ reduced basis in the same way as we did for our solutions:\n",
    "\n",
    "\\begin{equation}\n",
    "V(r; \\alpha)  \\approx V_\\text{EIM} (r; \\alpha)  = \\sum_k^m \\beta_k(\\alpha) V_k(r).\n",
    "\\end{equation}\n",
    "\n",
    "Fortunately, ROSE will handle all of these details for us, so we don't have to get our hands too dirty! Let's take a look at how to use ROSE to make ourselves a nice emulator.\n",
    "\n",
    "We will create training boundaries 20% above and below our mean values for the parameters, and therefore define the bounds of a hyper-box in our 11D parameter space that contains this region of interst. We will train our emulator with random samples of $\\alpha$ from this box, and we would like to be accurate throughout the entire box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20cc2891",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleTraining = 0.2\n",
    "\n",
    "bounds = np.array(\n",
    "    [\n",
    "        alphaCentral - np.fabs(alphaCentral * scaleTraining),\n",
    "        alphaCentral + np.fabs(alphaCentral * scaleTraining),\n",
    "    ]\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee49caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_points(npoints, bounds,initial_seed=None):\n",
    "    sampler = qmc.LatinHypercube(d=len(bounds), seed=initial_seed)\n",
    "    sample = sampler.random(npoints)\n",
    "    scaled = qmc.scale(sample, bounds[:, 0], bounds[:, 1])\n",
    "    return scaled\n",
    "\n",
    "\n",
    "n_test = 50\n",
    "n_train = 50\n",
    "\n",
    "seed_train=142857\n",
    "seed_test=142857*2\n",
    "\n",
    "training_samples = sample_points(n_train, bounds,initial_seed=seed_train)\n",
    "test_samples = sample_points(n_test, bounds,initial_seed=seed_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bab899",
   "metadata": {},
   "source": [
    "## Construct the Interaction, the High-Fidelity Solver, and the Emulator\n",
    "\n",
    "Great, we have all the points we need to sample. Now let's define an InteractionEIMSpace in ROSE, which encodes the original and Empirically-Interpolated potential we've defined for each partial wave. Then we will use this to construct our emulators and our High-Fidelity (HF) solver, and take a look at how snapshots of the HF solutions vary over our training space.  We will use the default EIM setup. ROSE will automatically use the exact potential for the HF solver, and the EIM decomposed potential for emulation.\n",
    "\n",
    "By the way, we like to call HF solutions of our system \"snapshots\". In this case, we use snapshots to refer to the test observables (differential cross sections), but we will also use it to refer to the training wavefunctions we generate with the HF solver, which ROSE uses to construct the reduced basis.\n",
    "\n",
    "We will start by using a reduced basis of 4 elements, and the same number of EIM terms as there are parameters in $\\boldsymbol{\\alpha}$; in this case, 11. We will pass in the bounds of our parameter space, and the `InteractionEIMSpace` object will automatically find 1000 (by default) well-distributed points in our parameter space to train the EIM factorization. Both these numbers can be easily changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cb78b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can invoke ROSE. Let's build an InteractionEIMSpace, running over lmax partial waves,\n",
    "# with the optical potential we defined above.\n",
    "interactions = rose.InteractionEIMSpace(\n",
    "    optical_potential,\n",
    "    nparams,\n",
    "    MU,\n",
    "    energy,\n",
    "    l_max,\n",
    "    is_complex=True,\n",
    "    spin_orbit_potential=spin_orbit_potential,\n",
    "    training_info=bounds,\n",
    "    n_basis=11\n",
    ")\n",
    "# that was easy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02fa51e",
   "metadata": {},
   "source": [
    "Now that we have our interaction, let's set up 1) a HF solver and 2) an emulator. In ROSE, these tasks are handled by the same object; `ScatteringAmplitudeEmulator`. We will set one up, and calculate snapshots of the cross sections at our test points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13cde2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 11/11 [01:21<00:00,  7.39s/it]\n",
      "/home/kyle/umich/rose/src/rose/utility.py:86: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.hstack([1/(2*s_c) * (3 - (s[ii]/s_c)**2), 1/s[jj]])\n"
     ]
    }
   ],
   "source": [
    "# let's build our first reduced basis emulator\n",
    "emulator = rose.ScatteringAmplitudeEmulator.from_train(\n",
    "    interactions,\n",
    "    training_samples,\n",
    "    l_max,\n",
    "    n_basis=5,\n",
    "    angles=angles / 180 * np.pi,\n",
    "    hf_tols=[\n",
    "        10 ** (-9),\n",
    "        10 ** (-9),\n",
    "    ],  # these are the relative and absolute tolerances for the HF Runge-Kutta solver\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db61f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▌                                        | 4/50 [00:33<06:17,  8.20s/it]"
     ]
    }
   ],
   "source": [
    "# calculate the exact differential cross section for the 50 test parameters we sampled\n",
    "test_CS = []\n",
    "for params in tqdm(test_samples):\n",
    "    xs = emulator.exact_xs(params)\n",
    "    test_CS.append(xs.dsdo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2ad145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's plot the differential scattering cross section for each of these samples test points!\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "\n",
    "\n",
    "for i in range(n_test):\n",
    "    ax.plot(angles, test_CS[i])\n",
    "ax.set_yscale(\"log\")\n",
    "plt.xlim([0, 180])\n",
    "plt.xlabel(r\"$\\theta$ [$^\\circ$]\")\n",
    "plt.ylabel(r\"$\\frac{d \\sigma}{d \\Omega}$ [mb/sr]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa44c446",
   "metadata": {},
   "source": [
    "Great, we have our test cross section! Now let's reproduce them with our emulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6573b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the exact differential cross section for the 50 test parameters we sampled\n",
    "test_CS_emu = []\n",
    "for params in tqdm(test_samples):\n",
    "    xs = emulator.emulate_xs(params)\n",
    "    test_CS_emu.append(xs.dsdo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f675e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "\n",
    "# only plot some of them so the plot isn't too cluttered\n",
    "for i in range(10):\n",
    "    p = ax.plot(angles, test_CS[i])\n",
    "    ax.plot(angles, test_CS_emu[i], linestyle= \"dashed\" ,color=p[0].get_color())\n",
    "\n",
    "    # ax.plot(angles, test_CS[i])\n",
    "    # ax.plot(angles, test_CS_emu[i], linestyle= \"dashed\" )\n",
    "\n",
    "legend_styles = [\n",
    "    Line2D([0], [0], color=\"k\", linestyle=\"--\"),\n",
    "    Line2D([0], [0], color=\"k\"),\n",
    "]\n",
    "ax.legend(legend_styles, [\"emulated\", \"high-fidelity\"])\n",
    "ax.set_yscale(\"log\")\n",
    "plt.xlim([0, 180])\n",
    "plt.xlabel(r\"$\\theta$ [$^\\circ$]\")\n",
    "plt.ylabel(r\"$\\frac{d \\sigma}{d \\Omega}$ [mb/sr]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaac778",
   "metadata": {},
   "source": [
    "This is not bad, but we can do better by optimizing the hyperparameters a bit. Many computational methods have one or more handles to trade off better accuracy at the cost of loss of speed. In the case of the reduced basis emulator we can directly change 1) the size of the reduced basis, and 2) the number of terms in the EIM expansion. Remember, we used 5 reduced basis elements, and 11 EIM terms. \n",
    "\n",
    "Let's write a little function that can test more configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb5bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emulator_trainer(sae_config: tuple):\n",
    "    r\"\"\"\n",
    "    build an emulator to specification of sae_config\n",
    "    Parameters:\n",
    "        sae_config (size of reduced basis, number of EIM terms)\n",
    "    \"\"\"\n",
    "\n",
    "    (n_basis, n_EIM) = sae_config\n",
    "\n",
    "    interaction_space_eim = rose.InteractionEIMSpace(\n",
    "        optical_potential,\n",
    "        nparams,\n",
    "        MU,\n",
    "        energy,\n",
    "        l_max,\n",
    "        bounds,\n",
    "        spin_orbit_potential=spin_orbit_potential,\n",
    "        is_complex=True,\n",
    "        n_basis=n_EIM,\n",
    "    )\n",
    "\n",
    "    emulator = rose.ScatteringAmplitudeEmulator.from_train(\n",
    "        interactions,\n",
    "        training_samples,\n",
    "        l_max,\n",
    "        n_basis=n_basis,\n",
    "        angles=angles / 180 * np.pi,\n",
    "        hf_tols=[\n",
    "            10 ** (-9),\n",
    "            10 ** (-9),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return emulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f0303",
   "metadata": {},
   "source": [
    "Great, now let's choose a few configurations for the emulator and compare them. Our metrics will be:\n",
    "1. time to generate solution\n",
    "2. accuracy of solution (relative to the HF solver with a very small tolerance)\n",
    "\n",
    "For each of the configs we run, we will set up the emulator, and calculate these 2 metrics. First, we will do the offline training for all the emulator configs. This is where most of the computational expense of an emulator comes in; training in the offline stage. Once each partial wave, at each paramater sample point, has it's reduced basis trained, the online stage, where we calculate observables, should be much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7605f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [basis size, number of terms in EIM decomposition]\n",
    "Sae_configs = [(3, 3),  (3, 5), (5,5), (7,7) ,(10, 10)]\n",
    "\n",
    "# set up the emulators for each config\n",
    "Sae_Emulators = {}\n",
    "\n",
    "for saeconfig in Sae_configs:\n",
    "    key = f\"sae_{saeconfig[0]}_{saeconfig[1]}\"\n",
    "    Sae_Emulators[key] = emulator_trainer(saeconfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae2326",
   "metadata": {},
   "source": [
    "We would like to compare the results of our emulartors to HF solvers at a variety of tolerances, to make sure using an emulator is actually worthwhile, as opposed to just cranking down the tolerances on our HF solver. To do that, let's also set up some \"dummy\" `ScatteringAmplitudeEmulators`; we will just use for their HF solvers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3efadd9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# log of tolerance\n",
    "HF_configs=[-1.5,-2,-3,-4] \n",
    "\n",
    "# set up the HF solvers for each config\n",
    "HF_Solvers={}\n",
    "\n",
    "for HFconfig in HF_configs:\n",
    "    key = f'HF_{-HFconfig}'\n",
    "    HF_Solvers[key]=rose.ScatteringAmplitudeEmulator.from_train(\n",
    "        interactions,\n",
    "        sample_points(2, bounds), # only 2 training points so training is quick\n",
    "        l_max,\n",
    "        n_basis = 2, # only 2 basis elements so trainnig is quick\n",
    "        angles = angles/180*np.pi,\n",
    "        hf_tols=[10**(HFconfig),10**(HFconfig)]) # we will only be using the HF solver here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3905cff9",
   "metadata": {},
   "source": [
    "We can compare a prediction comming from one of the emulators (5 basis for wave functions, 3 for EIM), one of the HF, and the original highest fidelity solver we employed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4f43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emu_choice=f\"sae_{Sae_configs[2][0]}_{Sae_configs[2][1]}\"\n",
    "HF_choice=f'HF_{-HF_configs[1]}'\n",
    "print(\"Emulator choice: \")\n",
    "print(emu_choice)\n",
    "print(\"HF choice: \")\n",
    "print(HF_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_param=test_samples[0]\n",
    "emulator_prediction=Sae_Emulators[emu_choice].emulate_xs(single_param).dsdo\n",
    "HF_prediction=HF_Solvers[HF_choice].exact_xs(single_param).dsdo\n",
    "Super_HF_prediction=test_CS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 3), dpi=300)\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "\n",
    "# only plot some of them so the plot isn't too cluttered\n",
    "\n",
    "ax.plot(angles, Super_HF_prediction,label='Super HF')\n",
    "ax.plot(angles, HF_prediction, label=\"high-fidelity \"+f' ({-HF_configs[1]})',linestyle='dashed')\n",
    "ax.plot(angles,emulator_prediction, label ='emulated '+ f\"({Sae_configs[2][0]},{Sae_configs[2][1]})\",linestyle='dashed')\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "ax.set_yscale(\"log\")\n",
    "plt.xlim([0, 180])\n",
    "plt.xlabel(r\"$\\theta$ [$^\\circ$]\")\n",
    "plt.ylabel(r\"$\\frac{d \\sigma}{d \\Omega}$ [mb/sr]\")\n",
    "plt.rc(\"xtick\", labelsize=10)\n",
    "plt.rc(\"ytick\", labelsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb20906",
   "metadata": {},
   "source": [
    "Great, we have trained all of our emulators and set up our HF solvers. Now let's write a function that calculates the metrics we've defined; accuracy and speed, for each sampled test parameter. We will then invoke it to get the metrics for our set of emulator configurations, and our HF solver configurations. We call this kind of analysis Computational Accuracy vs. Time (CAT) analysis, and the resulting plots, CAT plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAT_Data_Maker(CS_calculator, test_parameters, test_data):\n",
    "    # Both the predictions and the test_data are evaluated over all angles\n",
    "\n",
    "    prediction_list = []\n",
    "    times_list = []\n",
    "    for i in range(len(test_parameters)):\n",
    "        st = time.time()\n",
    "        predicted = CS_calculator(test_parameters[i]).dsdo\n",
    "        et = time.time()\n",
    "        prediction_list.append(predicted)\n",
    "        times_list.append(et - st)\n",
    "\n",
    "    residual_list = []\n",
    "    residual_list_median = []\n",
    "    for i in range(len(test_parameters)):\n",
    "        residual_list.append(\n",
    "            np.fabs((prediction_list[i] - test_data[i])) / (test_data[i])\n",
    "        )\n",
    "        residual_list_median.append(np.median(residual_list[i]))\n",
    "\n",
    "    return [times_list, residual_list_median, residual_list, prediction_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db33e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get times and residuals for emulation with each config\n",
    "CAT_Emulator_Data = {}\n",
    "\n",
    "for sae in tqdm(Sae_Emulators):\n",
    "    CAT_Data = CAT_Data_Maker(Sae_Emulators[sae].emulate_xs, test_samples, test_CS)\n",
    "\n",
    "    CAT_Emulator_Data[sae] = {\n",
    "        \"times\": CAT_Data[0],\n",
    "        \"median_residuals\": CAT_Data[1],\n",
    "        \"residuals_list\": CAT_Data[2],\n",
    "        \"full_predictions\": CAT_Data[3],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0949dd9e",
   "metadata": {},
   "source": [
    "See how quick it was to emulate the cross sections? That's what we mean by a fast online stage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973d60ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get times and residuals for the HF solver withb each config\n",
    "CAT_HF_Data = {}\n",
    "\n",
    "for HF in tqdm(HF_Solvers):\n",
    "    CAT_Data = CAT_Data_Maker(HF_Solvers[HF].exact_xs, test_samples, test_CS)\n",
    "\n",
    "    CAT_HF_Data[HF] = {\n",
    "        \"times\": CAT_Data[0],\n",
    "        \"median_residuals\": CAT_Data[1],\n",
    "        \"residuals_list\": CAT_Data[2],\n",
    "        \"full_predictions\": CAT_Data[3],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cefd98",
   "metadata": {},
   "source": [
    "Comparatively, calculating cross sections with the HF solver takes forever...\n",
    "\n",
    "## Generate the CAT Plot\n",
    "\n",
    "Now that we have the runtimes and residuals for each emulator and HF configuration, let's throw it all onto a nice CAT plot. A lot of the code bellow is done to create aesthetically pleasing CAT plots, you could always just plot the mean computation time vs the mean error for each emulation configuration in a simple way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee508be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some colors that Pablo likes:\n",
    "colors = [\n",
    "    \"#1f77b4\",\n",
    "    \"#ff7f0e\",\n",
    "    \"#2ca02c\",\n",
    "    \"#d62728\",\n",
    "    \"#9467bd\",\n",
    "    \"#8c564b\",\n",
    "    \"#e377c2\",\n",
    "    \"#7f7f7f\",\n",
    "    \"#bcbd22\",\n",
    "    \"#17becf\",\n",
    "] \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 7), dpi=400)\n",
    "\n",
    "custom_lines = []\n",
    "\n",
    "custom_lines.append(\n",
    "    Line2D(\n",
    "        [],\n",
    "        [],\n",
    "        color=\"w\",\n",
    "        marker=\"X\",\n",
    "        linestyle=\"None\",\n",
    "        markersize=20,\n",
    "        label=\"[$n_\\phi$, $n_U$]\",\n",
    "    )\n",
    ")\n",
    "i = 0\n",
    "for sae in Sae_Emulators:\n",
    "    data_sae = [\n",
    "        np.array(CAT_Emulator_Data[sae][\"times\"]),\n",
    "        np.array( [    np.median(CAT_Emulator_Data[sae][\"residuals_list\"][ii]) for ii in range(len(CAT_Emulator_Data[sae][\"residuals_list\"]))   ]  ),\n",
    "    ]\n",
    "    data_sae = np.array(data_sae)\n",
    "\n",
    "  \n",
    "    ax.scatter(data_sae[0], data_sae[1], s=7, color=colors[i],alpha=0.8)\n",
    "\n",
    "    custom_lines.append(\n",
    "        Line2D(\n",
    "            [],\n",
    "            [],\n",
    "            color=colors[i],\n",
    "            marker=\"o\",\n",
    "            linestyle=\"None\",\n",
    "            markersize=20,\n",
    "            label=str(Sae_configs[i]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    i = i + 1\n",
    "\n",
    "\n",
    "i = 0\n",
    "for HF in HF_Solvers:\n",
    "    data_hf = [\n",
    "        np.array(CAT_HF_Data[HF][\"times\"]),\n",
    "        np.array( [    np.median(CAT_HF_Data[HF][\"residuals_list\"][ii]) for ii in range(len(CAT_HF_Data[HF][\"residuals_list\"]))   ]  ),\n",
    "    ]\n",
    "    data_hf = np.array(data_hf)\n",
    "   \n",
    "    ax.scatter(data_hf[0], data_hf[1], s=5, color=\"b\")\n",
    "    i = i + 1\n",
    "\n",
    "\n",
    "custom_lines.append(\n",
    "    Line2D(\n",
    "        [], [], color=\"b\", marker=\"o\", linestyle=\"None\", markersize=20, label=\"HF\"\n",
    "    )\n",
    ")\n",
    "ax.legend(handles=custom_lines, fontsize=22, frameon=True, edgecolor=\"black\")\n",
    "ax.plot([10 ** (-4), 0.036], [0.1, 0.1], color=\"k\", linewidth=1, linestyle=\"dashed\")\n",
    "ax.plot([0.036, 0.036], [10 ** (-9), 0.1], color=\"k\", linewidth=1, linestyle=\"dashed\")\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Time per sample (s)\", fontsize=23)\n",
    "ax.set_ylabel(\n",
    "    r\"Median CS Error \", fontsize=23\n",
    ")\n",
    "plt.rc(\"xtick\", labelsize=23)\n",
    "plt.rc(\"ytick\", labelsize=23)\n",
    "\n",
    "plt.xlim(5 * 10 ** (-4), 5 * 10 ** (1))\n",
    "plt.ylim(10 ** (-5), 10 ** (1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eabddd",
   "metadata": {},
   "source": [
    "Great, now we can decide empirically which emulator configuration is the fastest for a given accuracy, and we can quantitatively see that the emulators are categorically superior to the HF solver when it comes to getting fast and accurate differential cross sections. The dashed black lines represent an (arbitrary) target for speed and accuracy: more than 1 million samples per hour and less than 0.1 median absolute error. Options (7,7) and (10,10) for the emulator fullfil both of these requirements, while none of the high fidelity solvers get near the target region.\n",
    "\n",
    "Notice, increasing the number of EIM terms can increase accuracy without making too much large impact on time. We would expect diminishing returns for more EIM terms, however, and if the error is dominated by a lack of enough wave function basis (as the case of the (3,5) emulator) then increasing the EIM terms will not improve the emulator at all. For basis size, since ROSE has to actually solve a system of equations proportional to this variable, we except the time to scale roughly with the square of the basis size, so the impact on time is much larger. Since we only trained with 50 samples, in this case increasing te basis number further will saturate the median error in around 10^-4, but further improvement can be done by providing more training points for ROSE.\n",
    "\n",
    "Let's plot a few cross sections in the test set from the (10,10) emulator and see how they look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d7db29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emulator = Sae_Emulators[\"sae_10_10\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "\n",
    "# only plot some of them so the plot isn't too cluttered\n",
    "for i in range(1):\n",
    "    p = ax.plot(angles, emulator.emulate_xs(test_samples[i]).dsdo, \"--\", alpha=0.5)\n",
    "    ax.plot(angles, test_CS[i], color=p[0].get_color(), alpha=0.5)\n",
    "    ax.plot(angles, emulator.emulate_dsdo(test_samples[i]), 'k')\n",
    "\n",
    "legend_styles = [\n",
    "    Line2D([0], [0], color=\"k\", linestyle=\"--\", alpha=0.5),\n",
    "    Line2D([0], [0], color=\"k\", alpha=0.5),\n",
    "]\n",
    "ax.legend(legend_styles, [\"emulated\", \"high-fidelity\"])\n",
    "ax.set_yscale(\"log\")\n",
    "plt.xlim([0, 180])\n",
    "plt.xlabel(r\"$\\theta$ [$^\\circ$]\", fontsize=23)\n",
    "plt.ylabel(r\"$\\frac{d \\sigma}{d \\Omega}$ [mb/sr]\", fontsize=23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d79534c",
   "metadata": {},
   "source": [
    "Wow, what an improvement! And notice how fast it was. We had to make the lines see-thru here because the emulated and the HF solutions basically agree exactly, and with a speedup of almost 3 orders of magnitude on average.\n",
    "\n",
    "In the next tutorial, we will use the 'best' emulator configuration we trained to quickly optimize the parameters in the optical model to experimental cross section data, with Bayesian uncertainty-quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088e1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ending_time=time.time()\n",
    "\n",
    "print(\"Total time to run the notebook (minutes):\")\n",
    "\n",
    "print(round((Ending_time-Starting_time)/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
